{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kSiMkjMcQQwI"
      },
      "outputs": [],
      "source": [
        "!pip install openai langchain python-dotenv -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo openai_api_key=\"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\" > .env\n"
      ],
      "metadata": {
        "id": "9XJ9mhg5Qbxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "openai.api_key = os.environ.get(\"openai_api_key\")"
      ],
      "metadata": {
        "id": "hhKlgHGDQobM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def disp_markdown(text: str) -> None:\n",
        "  display(Markdown(text))\n",
        ""
      ],
      "metadata": {
        "id": "K-fuGz7BQrSQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=os.environ.get(\"openai_api_key\"))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "JiARD_5fQtbs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "# The SystemMessage is associated with the system role\n",
        "system_message = SystemMessage(content=\"You are a food critic.\")\n",
        "\n",
        "# The HumanMessage is associated with the user role\n",
        "user_message = HumanMessage(content=\"Do you think Kraft Dinner constitues fine dining?\")\n",
        "\n",
        "# The AIMessage is associated with the assistant role\n",
        "assistant_message = AIMessage(content=\"Egads! No, it most certainly does not!\")\n",
        ""
      ],
      "metadata": {
        "id": "EZ80ev8pQw75"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_user_message = HumanMessage(content=\"What about Red Lobster, surely that is fine dining!\")\n",
        "\n",
        "# create the list of prompts\n",
        "list_of_prompts = [\n",
        "    system_message,\n",
        "    user_message,\n",
        "    assistant_message,\n",
        "    second_user_message\n",
        "]\n",
        "\n",
        "# we can just call our chat_model on the list of prompts!\n",
        "chat_model(list_of_prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqTZtKvwRmVe",
        "outputId": "b5d3f356-aa1e-458c-83f2-cb82d45dad34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Well, Red Lobster falls under the category of casual dining rather than fine dining. While they may serve seafood dishes that are enjoyable for many, the overall dining experience and the quality of ingredients may not meet the standards of fine dining. Fine dining typically involves meticulously prepared dishes using premium ingredients, expertly crafted flavors, attentive service, and an elegant atmosphere. However, if you're looking for a more laid-back seafood experience, Red Lobster can be a satisfactory choice.\", additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "# we can signify variables we want access to by wrapping them in {}\n",
        "system_prompt_template = \"You are an expert in {SUBJECT}, and you're currently feeling {MOOD}\"\n",
        "system_prompt_template = SystemMessagePromptTemplate.from_template(system_prompt_template)\n",
        "\n",
        "user_prompt_template = \"{CONTENT}\"\n",
        "user_prompt_template = HumanMessagePromptTemplate.from_template(user_prompt_template)\n",
        "\n",
        "# put them together into a ChatPromptTemplate\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_prompt_template, user_prompt_template])"
      ],
      "metadata": {
        "id": "eSv9kdAZRo_n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_chat_prompt = chat_prompt.format_prompt(SUBJECT=\"cheeses\", MOOD=\"quite tired\", CONTENT=\"Hi, what are the finest cheeses?\").to_messages()\n",
        "\n",
        "disp_markdown(chat_model(formatted_chat_prompt).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "mLxt8XdTRtH-",
        "outputId": "924d5606-39b1-4de4-cbcd-6441e81afeef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello! As an expert in cheeses, I can confidently say that there are many exquisite cheeses out there. However, since I'm feeling quite tired at the moment, I'll provide you with a list of some widely acclaimed favorites:\n\n1. Parmigiano Reggiano: A hard, aged Italian cheese with a rich, nutty flavor.\n2. Gruyère: A Swiss cheese with a smooth texture and a slightly sweet, nutty taste.\n3. Roquefort: A creamy blue cheese from France, known for its tangy, sharp flavor.\n4. Comté: A French cheese with a complex flavor profile, ranging from fruity to nutty.\n5. Manchego: A Spanish cheese made from sheep's milk, characterized by its buttery texture and slightly salty taste.\n6. Brie: A soft, creamy French cheese with a mild, buttery flavor.\n7. Cheddar: A versatile cheese with a range of flavors, from mild to extra sharp, originating from England.\n\nOf course, this is just a small selection, and there are countless other exceptional cheeses to explore from various regions around the world."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=chat_model, prompt=chat_prompt)\n",
        "\n",
        "disp_markdown(chain.run(SUBJECT=\"classic cars\", MOOD=\"angry\", CONTENT=\"Is the 67 Chevrolet Impala a good vehicle?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4kAlhPv3Rv76",
        "outputId": "94200c2c-5874-471b-9b1f-7417001e472b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "No, the 67 Chevrolet Impala is not a good vehicle. It is an exceptional vehicle. It is a classic American car that is highly sought after by collectors and enthusiasts. With its iconic design, powerful engine options, and smooth performance, the 67 Impala is considered one of the greatest cars of its era. It's a timeless classic that continues to captivate car lovers to this day. So, to answer your question, yes, the 67 Chevrolet Impala is an outstanding vehicle."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://erki.lap.ee/failid/raamatud/guide1.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IWQL3viR0en",
        "outputId": "37fd8eb2-da9a-4ae4-9910-84e528dc71fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-06 07:28:21--  https://erki.lap.ee/failid/raamatud/guide1.txt\n",
            "Resolving erki.lap.ee (erki.lap.ee)... 185.158.177.102\n",
            "Connecting to erki.lap.ee (erki.lap.ee)|185.158.177.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 291862 (285K) [text/plain]\n",
            "Saving to: ‘guide1.txt.1’\n",
            "\n",
            "guide1.txt.1        100%[===================>] 285.02K   314KB/s    in 0.9s    \n",
            "\n",
            "2023-09-06 07:28:23 (314 KB/s) - ‘guide1.txt.1’ saved [291862/291862]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"guide1.txt\") as f:\n",
        "    hitchhikersguide = f.read()"
      ],
      "metadata": {
        "id": "tcl__e2TR2_T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator = \"\\n\")\n",
        "texts = text_splitter.split_text(hitchhikersguide)"
      ],
      "metadata": {
        "id": "Nu1e3ijRR57o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "rnIGR0sfR7-D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install chromadb==0.3.22 tiktoken -q\n"
      ],
      "metadata": {
        "id": "R7Vl5A1CR-Or"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install chromadb -U"
      ],
      "metadata": {
        "id": "PTS3HYM6SVGr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic -q\n",
        "import chromadb\n"
      ],
      "metadata": {
        "id": "fdEtdt3aSAjx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.chroma import Chroma\n",
        "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))]).as_retriever()\n"
      ],
      "metadata": {
        "id": "qpGmit-pSJ-5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = \"What makes towels important?\"\n",
        "docs = docsearch.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "pWyC02vRXPX8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUmBJ8byZX0D",
        "outputId": "6d8d56fa-6413-4a4e-c048-f97abb935343"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"value - you can wrap it around you for warmth as you bound across\\nthe cold moons of Jaglan Beta; you can lie on it on the brilliant\\nmarble-sanded beaches of Santraginus V, inhaling  the  heady  sea\\nvapours;  you can sleep under it beneath the stars which shine so\\nredly on the desert world of Kakrafoon; use it  to  sail  a  mini\\nraft  down  the slow heavy river Moth; wet it for use in hand-to-\\nhand-combat; wrap it round your head to ward off noxious fumes or\\nto  avoid  the  gaze of the Ravenous Bugblatter Beast of Traal (a\\nmindboggingly stupid animal, it assumes that if you can't see it,\\nit  can't  see  you - daft as a bush, but very ravenous); you can\\nwave your towel in emergencies  as  a  distress  signal,  and  of\\ncourse  dry  yourself  off  with it if it still seems to be clean\\nenough.\\n \\nMore importantly, a towel has immense  psychological  value.  For\\nsome reason, if a strag (strag: non-hitch hiker) discovers that a\\nhitch hiker has his towel with him, he will automatically  assume\", metadata={'source': '36'})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "query = \"What makes towels important?\"\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "EGIj3R5WZZ75",
        "outputId": "bb8749c7-39fd-4645-c5a8-6cdd72f5e540"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Towels have immense psychological value. For some reason, if a strag discovers that a hitch hiker has his towel with him, he will automatically assume that he is also in possession of a toothbrush, face flannel, soap, tin of biscuits, flask, compass, map, ball of string, gnat spray, wet weather gear, space suit etc., etc. Furthermore, the strag will then happily lend the hitch hiker any of these or a dozen other items that the hitch hiker might accidentally have \"lost\". What the strag will think is that any man who can hitch the length and breadth of the galaxy, rough it, slum it, struggle against terrible odds, win through, and still knows where his towel is is clearly a man to be reckoned with.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n"
      ],
      "metadata": {
        "id": "SXqvD_BZZkXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TheMITTech/shakespeare\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toFapMZDZcgc",
        "outputId": "c1d69e7e-a4d7-4dcd-c10b-4335ff94573e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'shakespeare'...\n",
            "remote: Enumerating objects: 2187, done.\u001b[K\n",
            "remote: Total 2187 (delta 0), reused 0 (delta 0), pack-reused 2187\u001b[K\n",
            "Receiving objects: 100% (2187/2187), 5.95 MiB | 12.43 MiB/s, done.\n",
            "Resolving deltas: 100% (1135/1135), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "files = glob(\"./shakespeare/**/*.html\")"
      ],
      "metadata": {
        "id": "lox62mX5Zra2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "os.mkdir('./data')\n",
        "destination_folder = './data/'\n",
        "\n",
        "for html_file in files:\n",
        "  shutil.move(html_file, destination_folder + html_file.split(\"/\")[-1])"
      ],
      "metadata": {
        "id": "yKcjYtcPZt09"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 -q\n"
      ],
      "metadata": {
        "id": "_WdeAObmZvnH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import BSHTMLLoader, DirectoryLoader\n",
        "\n",
        "bshtml_dir_loader = DirectoryLoader('./data/', loader_cls=BSHTMLLoader)\n",
        "\n",
        "data = bshtml_dir_loader.load()"
      ],
      "metadata": {
        "id": "HN0IGrSBZxuz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "7Yc45R9qZz7Y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"vector_db\"\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "_79heZP0Z1qh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vectordb.persist()\n",
        "vectordb = None\n",
        ""
      ],
      "metadata": {
        "id": "EgVo1xv3Z7bc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
      ],
      "metadata": {
        "id": "2zwY5jKcaQ0l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")"
      ],
      "metadata": {
        "id": "MR7vYxC5aTXs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_retriever = vectordb.as_retriever()\n"
      ],
      "metadata": {
        "id": "lBR8WMu3aVmC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "shakespeare_qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=doc_retriever)"
      ],
      "metadata": {
        "id": "cgDanDpxaXvT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_qa.run(\"Who is Hamlet'?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "t1hDzituabJ1",
        "outputId": "4ddf766a-3590-48d7-9474-76640624d3b8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hamlet is the protagonist of William Shakespeare's play of the same name. He is the Prince of Denmark, son of the deceased King Hamlet and his wife, Queen Gertrude. The play revolves around Hamlet's quest for revenge against his uncle, Claudius, who murdered his father and took the throne.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y0m_ZV7ae8Z",
        "outputId": "0b5c474c-9339-4475-84b6-763dd2f64fd9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "PdrUgZ1-al1F"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities import SerpAPIWrapper\n",
        "\n",
        "search = SerpAPIWrapper()\n"
      ],
      "metadata": {
        "id": "BFy70uDgasi_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMMathChain, SerpAPIWrapper\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Shakespeare QA System\",\n",
        "        func=shakespeare_qa.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare's works. Input should be a fully formed question.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"SERP API Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "YHM00wTravlH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
      ],
      "metadata": {
        "id": "fFL_9d_Jax3m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is Hamlet and more importantly who is hamlet?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "z55Hrtpfaz-W",
        "outputId": "55dc8582-a18e-47dd-b39d-962c11b29eda"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThis question is about Shakespeare's work, so I should use the Shakespeare QA System.\n",
            "Action: Shakespeare QA System\n",
            "Action Input: What is Hamlet and who is Hamlet in Shakespeare's work?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\"Hamlet\" is a tragedy written by William Shakespeare. It is one of his most popular works. The character Hamlet is the protagonist of the play. He is the Prince of Denmark, son of the recently deceased King Hamlet, and nephew of King Claudius, his father's brother and successor. The play follows Hamlet's quest for revenge against Claudius, who murdered his father.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: \"Hamlet\" is a tragedy written by William Shakespeare and is one of his most popular works. The character Hamlet is the protagonist of the play. He is the Prince of Denmark, son of the recently deceased King Hamlet, and nephew of King Claudius, his father's brother and successor. The play follows Hamlet's quest for revenge against Claudius, who murdered his father.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Hamlet\" is a tragedy written by William Shakespeare and is one of his most popular works. The character Hamlet is the protagonist of the play. He is the Prince of Denmark, son of the recently deceased King Hamlet, and nephew of King Claudius, his father\\'s brother and successor. The play follows Hamlet\\'s quest for revenge against Claudius, who murdered his father.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "readonlymemory = ReadOnlySharedMemory(memory=memory)"
      ],
      "metadata": {
        "id": "jhS8Lr8la3s5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=doc_retriever, memory=readonlymemory)\n"
      ],
      "metadata": {
        "id": "R73CmCEua943"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Shakespeare QA System\",\n",
        "        func=shakespeare_qa.run,\n",
        "        description=\"useful for when you need to answer questions about Shakespeare's works. Input should be a fully formed question.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"SERP API Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\"\n",
        "    ),\n",
        "]\n",
        ""
      ],
      "metadata": {
        "id": "0esXXlrFbG0l"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
        "\n",
        "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
        "suffix = \"\"\"Begin!\"\n",
        "\n",
        "{chat_history}\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
        ")"
      ],
      "metadata": {
        "id": "fH2hoPmAbJia"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, LLMChain, PromptTemplate\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
      ],
      "metadata": {
        "id": "2ykKpyDdbMRy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
      ],
      "metadata": {
        "id": "LV-t8-ombOf8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"Who is Hamlet and What is Hamlet?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "MzUkosUKbRFK",
        "outputId": "c81917ee-c677-4ecf-a3b7-e431bd4885c3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The question is about Shakespeare's work, Hamlet. I should use the Shakespeare QA System to answer this question.\n",
            "Action: Shakespeare QA System\n",
            "Action Input: Who is Hamlet in Shakespeare's works?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mHamlet is the protagonist of William Shakespeare's tragedy of the same name, \"Hamlet\". He is the Prince of Denmark, son of the deceased King Hamlet and Queen Gertrude. The play revolves around his struggle to avenge his father's murder.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have the answer to the first part of the question. Now I need to answer the second part of the question: What is Hamlet?\n",
            "Action: Shakespeare QA System\n",
            "Action Input: What is the play Hamlet about?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\"Hamlet\" is a tragedy written by William Shakespeare. It's about Prince Hamlet's revenge on his uncle Claudius for murdering King Hamlet, Claudius's brother and Prince Hamlet's father, and then succeeding to the throne and taking Gertrude, the old king's widow and Prince Hamlet's mother, as his wife. The play explores themes of revenge, treachery, moral corruption, and the consequences of indecision.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: Hamlet is the protagonist of William Shakespeare's tragedy, \"Hamlet\". He is the Prince of Denmark, son of the deceased King Hamlet and Queen Gertrude. The play, \"Hamlet\", is about Prince Hamlet's revenge on his uncle Claudius for murdering King Hamlet, Claudius's brother and Prince Hamlet's father, and then succeeding to the throne and taking Gertrude, the old king's widow and Prince Hamlet's mother, as his wife. The play explores themes of revenge, treachery, moral corruption, and the consequences of indecision.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hamlet is the protagonist of William Shakespeare\\'s tragedy, \"Hamlet\". He is the Prince of Denmark, son of the deceased King Hamlet and Queen Gertrude. The play, \"Hamlet\", is about Prince Hamlet\\'s revenge on his uncle Claudius for murdering King Hamlet, Claudius\\'s brother and Prince Hamlet\\'s father, and then succeeding to the throne and taking Gertrude, the old king\\'s widow and Prince Hamlet\\'s mother, as his wife. The play explores themes of revenge, treachery, moral corruption, and the consequences of indecision.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"What age was he in the play?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "-lnPJdu-bU-v",
        "outputId": "eea5356d-2ecf-475e-dfd7-86f71d122721"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: This question is about a character in a Shakespeare play, so I should use the Shakespeare QA System.\n",
            "Action: Shakespeare QA System\n",
            "Action Input: How old is Hamlet in the play \"Hamlet\"?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe text provided does not specify Hamlet's age in the play \"Hamlet\".\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: The text of the play \"Hamlet\" does not specify Hamlet's exact age.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The text of the play \"Hamlet\" does not specify Hamlet\\'s exact age.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"Did he live through the play?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "qcJ8wtwSboPR",
        "outputId": "b7ad1a79-854f-4a1d-99e3-fe584de9353d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: This question is about the plot of a Shakespeare play.\n",
            "Action: Shakespeare QA System\n",
            "Action Input: Does Hamlet survive at the end of the play?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo, Hamlet does not survive at the end of the play. He dies from poison.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: No, Hamlet does not live through the play. He dies from poison.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No, Hamlet does not live through the play. He dies from poison.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"What age did you think he was if you approximate without directly reading it from the play? You make the inference on his acts and ages of people in his life\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "z1H1MLN-bswW",
        "outputId": "c0b673c8-bbf2-4ae3-8851-2a80e99f5a75"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: This question requires knowledge about the character Hamlet from Shakespeare's play. I should use the Shakespeare QA System to find an answer.\n",
            "Action: Shakespeare QA System\n",
            "Action Input: What is the approximate age of Hamlet based on his actions and the ages of people in his life in the play?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe text provided does not give specific information about Hamlet's age or the ages of people in his life. However, in the full play of Hamlet by William Shakespeare, it is suggested that Hamlet is around 30 years old.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: Based on his actions and the ages of people in his life in the play, it is suggested that Hamlet is around 30 years old.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on his actions and the ages of people in his life in the play, it is suggested that Hamlet is around 30 years old.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface-cli login\n"
      ],
      "metadata": {
        "id": "n9Wdhpxpbz2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}